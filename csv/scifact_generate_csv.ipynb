{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from utils import avg, evidence_to_mask\n",
    "\n",
    "def to_data_df(df, data_dir):\n",
    "    data_df = []\n",
    "    columns = ['text','classification', 'rationale','query']\n",
    "    for i in tqdm(range(len(df))):\n",
    "        df_row = df.loc[i]\n",
    "        doc_ids = df_row['docids']\n",
    "        query = df_row['query']\n",
    "        evidence_list = df_row['evidences']\n",
    "        if evidence_list:\n",
    "            evidence_list = [x for xx in evidence_list for x in xx]\n",
    "        classification = df_row['classification']\n",
    "        \n",
    "        text = ''\n",
    "        for doc in doc_ids:\n",
    "            file = f'{data_dir}/docs/{doc}'\n",
    "            if os.path.isfile(file):\n",
    "                f = open(file, 'r', encoding=\"utf-8\") \n",
    "                for line in f.readlines():\n",
    "                    text += line.rstrip() + ' '\n",
    "            else:\n",
    "                print(\"???\")\n",
    "                print(file)\n",
    "                quit()\n",
    "        \n",
    "        tokens = text.split()\n",
    "        rationale_mask = evidence_to_mask(tokens, evidence_list)\n",
    "        \n",
    "        # joining text and query with [SEP]\n",
    "        QA = f\"{query} [SEP] {text}\"\n",
    "        rationale_mask = [1]*(len(query.split())+1) + rationale_mask\n",
    "        \n",
    "#         QA = f\"{text}[SEP] {query}\"\n",
    "#         rationale_mask = rationale_mask + [1]*(len(query.split())+1) \n",
    "         \n",
    "        data_df.append([QA, classification, rationale_mask, query])\n",
    "    data_df = pd.DataFrame(data_df, columns=columns)\n",
    "    return data_df\n",
    "    \n",
    "    data_df_shuffled=data_df.sample(frac=1).reset_index(drop=True)\n",
    "    return data_df_shuffled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"scifact\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = f'../data/{dataset}'\n",
    "train = pd.read_json(f'{data_dir}/train.jsonl', lines=True)\n",
    "test = pd.read_json(f'{data_dir}/test.jsonl', lines=True)\n",
    "val = pd.read_json(f'{data_dir}/val.jsonl', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 405/405 [00:00<00:00, 1427.99it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 188/188 [00:00<00:00, 1485.26it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 1325.72it/s]\n"
     ]
    }
   ],
   "source": [
    "train_data_df = to_data_df(train, data_dir)\n",
    "train_data_df.to_csv(f\"{dataset}/train.csv\",index_label=\"id\")\n",
    "test_data_df = to_data_df(test, data_dir)\n",
    "test_data_df.to_csv(f\"{dataset}/test.csv\",index_label=\"id\")\n",
    "val_data_df = to_data_df(val, data_dir)\n",
    "val_data_df.to_csv(f\"{dataset}/val.csv\",index_label=\"id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SANITY CHECK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rationale_check(text,rationale):\n",
    "    tokens = text.split()\n",
    "    out = \"\"\n",
    "    for i, b in enumerate(rationale):\n",
    "        if b:\n",
    "           out += tokens[i] + \" \"\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = test_data_df\n",
    "import json\n",
    "\n",
    "def reduce_by_alpha(text, rationale, fidelity_type=\"sufficiency\"):\n",
    "    reduced_text = \"\"\n",
    "    # whitespace tokenization\n",
    "    tokens = text.split()\n",
    "\n",
    "    for idx in range(len(tokens)):\n",
    "        try:\n",
    "            if fidelity_type == \"sufficiency\" and rationale[idx] >= 0.5:\n",
    "                reduced_text = reduced_text + tokens[idx] + \" \"\n",
    "            elif fidelity_type == \"comprehensiveness\" and rationale[idx] < 0.5:\n",
    "                reduced_text = reduced_text + tokens[idx] + \" \"\n",
    "        except Exception as e:\n",
    "            if fidelity_type == \"comprehensiveness\":\n",
    "                reduced_text = reduced_text + tokens[idx] + \" \"\n",
    "\n",
    "    # removed the last space from the text\n",
    "    if len(reduced_text) > 0:\n",
    "        reduced_text = reduced_text[:-1]\n",
    "\n",
    "    return reduced_text\n",
    "\n",
    "data_df = data_df[data_df['rationale'].notna()]\n",
    "data_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "\n",
    "data_df[\"sufficiency_text\"] = data_df[\n",
    "    [\"text\", \"rationale\"]].apply(lambda s: reduce_by_alpha(*s, fidelity_type=\"sufficiency\"), axis=1)\n",
    "data_df[\"comprehensiveness_text\"] = data_df[\n",
    "    [\"text\", \"rationale\"]].apply(lambda s: reduce_by_alpha(*s, fidelity_type=\"comprehensiveness\"), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1,000 genomes project enables mapping of genetic sequence variation consisting of rare variants with larger penetrance effects than common variants. [SEP] We propose as an alternative explanation that variants much less common than the associated one may create \" synthetic associations \" by occurring , stochastically , more often in association with one of the alleles at the common site versus the other allele . We show that they are not only possible , but inevitable , and that under simple but reasonable genetic models , they are likely to account for or contribute to many of the recently identified signals reported in genome-wide association studies . In conclusion , uncommon or rare genetic variants can easily create synthetic associations that are credited to common variants , and this possibility requires careful consideration in the interpretation and follow up of GWAS signals .'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df['sufficiency_text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "annotation_id                                                     3\n",
       "query             1,000 genomes project enables mapping of genet...\n",
       "evidences         [[{'text': 'We propose as an alternative expla...\n",
       "classification                                             SUPPORTS\n",
       "query_type                                                      NaN\n",
       "docids                                                   [14717500]\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1 in 5 million in UK have abnormal PrP positivity. [SEP] OBJECTIVES To carry out a further survey of archived appendix samples to understand better the differences between existing estimates of the prevalence of subclinical infection with prions after the bovine spongiform encephalopathy epizootic and to see whether a broader birth cohort was affected , and to understand better the implications for the management of blood and blood products and for the handling of surgical instruments . DESIGN Irreversibly unlinked and anonymised large scale survey of archived appendix samples . SETTING Archived appendix samples from the pathology departments of 41 UK hospitals participating in the earlier survey , and additional hospitals in regions with lower levels of participation in that survey . SAMPLE 32,441 archived appendix samples fixed in formalin and embedded in paraffin and tested for the presence of abnormal prion protein ( PrP ) . RESULTS Of the 32,441 appendix samples 16 were positive for abnormal PrP , indicating an overall prevalence of 493 per million population ( 95 % confidence interval 282 to 801 per million ) . The prevalence in those born in 1941 - 60 ( 733 per million , 269 to 1596 per million ) did not differ significantly from those born between 1961 and 1985 ( 412 per million , 198 to 758 per million ) and was similar in both sexes and across the three broad geographical areas sampled . Genetic testing of the positive specimens for the genotype at PRNP codon 129 revealed a high proportion that were valine homozygous compared with the frequency in the normal population , and in stark contrast with confirmed clinical cases of vCJD , all of which were methionine homozygous at PRNP codon 129 . CONCLUSIONS This study corroborates previous studies and suggests a high prevalence of infection with abnormal PrP , indicating vCJD carrier status in the population compared with the 177 vCJD cases to date . These findings have important implications for the management of blood and blood products and for the handling of surgical instruments . '"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_df.iloc[0]['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA STATS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_class_stats(train_df, test_df, val_df):\n",
    "    text_lens_0 = []\n",
    "    text_lens_1 = []\n",
    "    rationale_lens_0 = []\n",
    "    rationale_lens_1 = []\n",
    "    rationale_percent_0 = []\n",
    "    rationale_percent_1 = []\n",
    "    class_distribution = [0,0]\n",
    "    for df in [train_df, test_df, val_df]:\n",
    "        for i in range(len(df)):\n",
    "            df_row = df.loc[i]\n",
    "            clas = df_row['classification']\n",
    "            text = df_row['text']\n",
    "            rationale = df_row['rationale']\n",
    "            query = df_row['query']\n",
    "            \n",
    "            query_len = len(query.split())\n",
    "            text_len = len(text.split()) - query_len - 1\n",
    "            rationale_len = rationale.count(1) - query_len - 1\n",
    "            rationale_percent = rationale_len/text_len\n",
    "            if clas == \"REFUTES\":\n",
    "                text_lens_0.append(text_len)\n",
    "                rationale_lens_0.append(rationale_len)\n",
    "                rationale_percent_0.append(rationale_percent)\n",
    "                class_distribution[0] += 1\n",
    "            else:\n",
    "                text_lens_1.append(text_len)\n",
    "                rationale_lens_1.append(rationale_len)\n",
    "                rationale_percent_1.append(rationale_percent)\n",
    "                class_distribution[1] += 1\n",
    "                \n",
    "    all_stats = {\"text_lens_0\": text_lens_0,\n",
    "                 \"text_lens_1\": text_lens_1,\n",
    "                 \"text_lens_all\":text_lens_0 + text_lens_1,\n",
    "                 \"rationale_lens_0\":rationale_lens_0,\n",
    "                 \"rationale_lens_1\":rationale_lens_1,\n",
    "                 \"rationale_lens_all\":rationale_lens_0 + rationale_lens_1,\n",
    "                 \"rationale_percent_0\": rationale_percent_0,\n",
    "                 \"rationale_percent_1\": rationale_percent_1,\n",
    "                 \"rationale_percent_all\": rationale_percent_0 + rationale_percent_1,\n",
    "                 \"class_distr\":[class_distribution[0]/sum(class_distribution),class_distribution[1]/sum(class_distribution)]\n",
    "                }\n",
    "    return all_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text_lens_0: 338.1097046413502\n",
      "text_lens_1: 290.7872807017544\n",
      "text_lens_all: 306.97113997113996\n",
      "rationale_lens_0: 75.33755274261604\n",
      "rationale_lens_1: 64.48245614035088\n",
      "rationale_lens_all: 68.1948051948052\n",
      "rationale_percent_0: 0.24197325510418663\n",
      "rationale_percent_1: 0.24247460908892945\n",
      "rationale_percent_all: 0.24230315036687455\n",
      "class_distr: 0.5\n",
      "[0.341991341991342, 0.658008658008658]\n"
     ]
    }
   ],
   "source": [
    "all_stats = generate_class_stats(train_data_df,test_data_df,val_data_df)\n",
    "for key,val in all_stats.items():\n",
    "    print(f\"{key}: {avg(val)}\")\n",
    "print(all_stats[\"class_distr\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RESULTS Of the 32,441 appendix samples 16 were positive for abnormal PrP , indicating an overall prevalence of 493 per million population ( 95 % confidence interval 282 to 801 per million ) . [SEP] 1 in 5 million in UK have abnormal PrP positivity. '"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rationale_check(train_data_df.iloc[0]['text'],train_data_df.iloc[0]['rationale'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'text': 'RESULTS Of the 32,441 appendix samples 16 were positive for abnormal PrP , indicating an overall prevalence of 493 per million population ( 95 % confidence interval 282 to 801 per million ) .',\n",
       "   'docid': '13734012',\n",
       "   'start_token': 136,\n",
       "   'end_token': 170,\n",
       "   'start_sentence': 4,\n",
       "   'end_sentence': 5}]]"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.iloc[0]['evidences']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text              OBJECTIVES To carry out a further survey of ar...\n",
       "classification                                              REFUTES\n",
       "rationale         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
       "query             1 in 5 million in UK have abnormal PrP positiv...\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_df.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
