JPEG JPEG ( ) is a commonly used method of lossy compression for digital images , particularly for those images produced by digital photography .
The degree of compression can be adjusted , allowing a selectable tradeoff between storage size and image quality .
JPEG typically achieves 10:1 compression with little perceptible loss in image quality .
JPEG compression is used in a number of image file formats .
JPEG /
Exif is the most common image format used by digital cameras and other photographic image capture devices ; along with JPEG / JFIF , it is the most common format for storing and transmitting photographic images on the World Wide Web .
These format variations are often not distinguished , and are simply called JPEG .
The term " JPEG " is an initialism / acronym for the Joint Photographic Experts Group , which created the standard .
The MIME media type for JPEG is image / jpeg , except in older Internet Explorer versions , which provides a MIME type of image / pjpeg when uploading JPEG images .
JPEG files usually have a filename extension of .jpg
or .jpeg .
JPEG
/ JFIF supports a maximum image size of 65,535×65,535 pixels , hence up to 4 gigapixels for an aspect ratio of 1:1 .
THE JPEG STANDARD Section::::The JPEG standard .
" JPEG " stands for Joint Photographic Experts Group , the name of the committee that created the JPEG standard and also other still picture coding standards .
The " Joint " stood for ISO TC97 WG8 and CCITT SGVIII .
In 1987 ISO TC 97 became ISO / IEC JTC1 and in 1992 CCITT became ITU - T. Currently on the JTC1 side JPEG is one of two sub - groups of ISO / IEC Joint Technical Committee 1 , Subcommittee 29 , Working Group 1 ( ISO / IEC JTC 1
/ SC
29 / WG 1 ) – titled as Coding of still pictures .
On the ITU - T side ITU - T SG16 is the respective body .
The original JPEG Group was organized in 1986 , issuing the first JPEG standard in 1992 , which was approved in September 1992 as ITU - T Recommendation T.81 and in 1994 as ISO / IEC 10918 - 1 .
The JPEG standard specifies the codec , which defines how an image is compressed into a stream of bytes and decompressed back into an image , but not the file format used to contain that stream .
The Exif and JFIF standards define the commonly used file formats for interchange of JPEG - compressed images .
JPEG standards are formally named as Information technology – Digital compression and coding of continuous - tone still images .
ISO / IEC 10918 consists of the following parts : + Digital compression and coding of continuous - tone still images – Parts !
Description
Ecma International TR/98 specifies the JPEG File Interchange Format ( JFIF )
; the first edition was published in June 2009 .
TYPICAL USAGE Section::::Typical usage .
The JPEG compression algorithm is at its best on photographs and paintings of realistic scenes with smooth variations of tone and color .
For web usage , where reducing the amount of data used for an image is important for responsive presentation , JPEG 's compression benefits make JPEG popular .
JPEG /
Exif is also the most common format saved by digital cameras .
However , JPEG is not well suited for line drawings and other textual or iconic graphics , where the sharp contrasts between adjacent pixels can cause noticeable artifacts .
Such images are better saved in a lossless graphics format such as TIFF , GIF , PNG , or a raw image format .
The JPEG standard includes a lossless coding mode , but that mode is not supported in most products .
As the typical use of JPEG is a lossy compression method , which reduces the image fidelity , it is inappropriate for exact reproduction of imaging data ( such as some scientific and medical imaging applications and certain technical image processing work ) .
JPEG is also not well suited to files that will undergo multiple edits , as some image quality is lost each time the image is recompressed , particularly if the image is cropped or shifted , or if encoding parameters are changed – see digital generation loss for details .
To prevent image information loss during sequential and repetitive editing , the first edit can be saved in a lossless format , subsequently edited in that format , then finally published as JPEG for distribution .
JPEG COMPRESSION
Section::::JPEG compression .
JPEG uses a lossy form of compression based on the discrete cosine transform ( DCT ) .
This mathematical operation converts each frame / field of the video source from the spatial ( 2D ) domain into the frequency domain ( a.k.a . transform domain ) .
A perceptual model based loosely on the human psychovisual system discards high - frequency information , i.e. sharp transitions in intensity , and color hue .
In the transform domain , the process of reducing information is called quantization .
In simpler terms , quantization is a method for optimally reducing a large number scale ( with different occurrences of each number ) into a smaller one , and the transform - domain is a convenient representation of the image because the high - frequency coefficients , which contribute less to the overall picture than other coefficients , are characteristically small - values with high compressibility .
The quantized coefficients are then sequenced and losslessly packed into the output bitstream .
Nearly all software implementations of JPEG permit user control over the compression - ratio ( as well as other optional parameters ) , allowing the user to trade off picture - quality for smaller file size .
In embedded applications ( such as miniDV , which uses a similar DCT - compression scheme ) , the parameters are pre - selected and fixed for the application .
The compression method is usually lossy , meaning that some original image information is lost and can not be restored , possibly affecting image quality .
There is an optional lossless mode defined in the JPEG standard .
However , this mode is not widely supported in products .
There is also an interlaced progressive JPEG format , in which data is compressed in multiple passes of progressively higher detail .
This is ideal for large images that will be displayed while downloading over a slow connection , allowing a reasonable preview after receiving only a portion of the data .
However , support for progressive JPEGs is not universal .
When progressive JPEGs are received by programs that do not support them ( such as versions of Internet Explorer before Windows 7 ) the software displays the image only after it has been completely downloaded .
There are also many medical imaging , traffic and camera applications that create and process
12-bit JPEG images both grayscale and color .
12-bit JPEG format is included in Extended part of the JPEG specification .
Libjpeg codec supports 12-bit JPEG and there even exists a high performance version .
LOSSLESS EDITING
Section::::Lossless editing .
A number of alterations to a JPEG image can be performed losslessly ( that is , without recompression and the associated quality loss ) as long as the image size is a multiple of 1 MCU block ( Minimum Coded Unit ) ( usually 16 pixels in both directions , for 4:2:0 chroma subsampling ) .
Utilities that implement this include : * jpegtran and its GUI , Jpegcrop .
* IrfanView using " JPG Lossless Crop ( PlugIn ) " and " JPG Lossless Rotation ( PlugIn ) " , which require installing the JPG_TRANSFORM plugin .
* FastStone Image Viewer using " Lossless Crop to File " and " JPEG Lossless Rotate " .
* XnViewMP using " JPEG lossless transformations " .
*
ACDSee supports lossless rotation ( but not lossless cropping ) with its " Force lossless JPEG operations " option .
Blocks can be rotated in 90-degree increments , flipped in the horizontal , vertical and diagonal axes and moved about in the image .
Not all blocks from the original image need to be used in the modified one .
The top and left edge of a JPEG image must lie on an 8 × 8 pixel block boundary , but the bottom and right edge need not do so .
This limits the possible lossless crop operations , and also prevents flips and rotations of an image whose bottom or right edge does not lie on a block boundary for all channels ( because the edge would end up on top or left , where – as aforementioned – a block boundary is obligatory ) .
Rotations where the image is not a multiple of 8 or 16 , which value depends upon the chroma subsampling , are not lossless .
Rotating such an image causes the blocks to be recomputed which results in loss of quality .
When using lossless cropping , if the bottom or right side of the crop region is not on a block boundary then the rest of the data from the partially used blocks will still be present in the cropped file and can be recovered .
It is also possible to transform between baseline and progressive formats without any loss of quality , since the only difference is the order in which the coefficients are placed in the file .
Furthermore , several JPEG images can be losslessly joined together , as long as they were saved with the same quality and the edges coincide with block boundaries .
JPEG FILES
Section::::JPEG files .
The file format known as " JPEG Interchange Format " ( JIF ) is specified in Annex B of the standard .
However , this " pure " file format is rarely used , primarily because of the difficulty of programming encoders and decoders that fully implement all aspects of the standard and because of certain shortcomings of the standard :
* Color space definition
*
Component sub - sampling registration * Pixel aspect ratio definition .
Several additional standards have evolved to address these issues .
The first of these , released in 1992 , was JPEG File Interchange Format ( or JFIF ) , followed in recent years by Exchangeable image file format ( Exif ) and ICC color profiles .
Both of these formats use the actual JIF byte layout , consisting of different markers , but in addition employ one of the JIF standard 's extension points , namely the application markers : JFIF uses APP0 , while Exif uses APP1 .
Within these segments of the file , that were left for future use in the JIF standard and are n't read by it , these standards add specific metadata .
Thus , in some ways JFIF is a cutdown version of the JIF standard in that it specifies certain constraints ( such as not allowing all the different encoding modes ) , while in other ways it is an extension of JIF due to the added metadata .
The documentation for the original JFIF standard states : Image files that employ JPEG compression are commonly called " JPEG files " , and are stored in variants of the JIF image format .
Most image capture devices ( such as digital cameras ) that output JPEG are actually creating files in the Exif format , the format that the camera industry has standardized on for metadata interchange .
On the other hand , since the Exif standard does not allow color profiles , most image editing software stores JPEG in JFIF format , and also include the APP1 segment from the Exif file to include the metadata in an almost - compliant way ; the JFIF standard is interpreted somewhat flexibly .
Strictly speaking , the JFIF and Exif standards are incompatible because each specifies that its marker segment ( APP0 or APP1 , respectively ) appear first .
In practice , most JPEG files contain a JFIF marker segment that precedes the Exif header .
This allows older readers to correctly handle the older format JFIF segment , while newer readers also decode the following Exif segment , being less strict about requiring it to appear first .
JPEG FILENAME EXTENSIONS Section::::JPEG filename extensions .
The most common filename extensions for files employing JPEG compression are .jpg
and .jpeg , though .jpe , .jfif
and .jif are also used .
It is also possible for JPEG data to be embedded in other file types – TIFF encoded files often embed a JPEG image as a thumbnail of the main image ; and MP3 files can contain a JPEG of cover art , in the ID3v2 tag .
COLOR PROFILE
Section::::Color profile .
Many JPEG files embed an ICC color profile ( color space ) .
Commonly used color profiles include sRGB and Adobe RGB .
Because these color spaces use a non - linear transformation , the dynamic range of an 8-bit JPEG file is about 11 stops ; see gamma curve .
SYNTAX AND STRUCTURE Section::::Syntax and structure .
A JPEG image consists of a sequence of segments , each beginning with a marker , each of which begins with a 0xFF byte followed by a byte indicating what kind of marker it is .
Some markers consist of just those two bytes ; others are followed by two bytes ( high then low ) indicating the length of marker - specific payload data that follows .
( The length includes the two bytes for the length , but not the two bytes for the marker . )
Some markers are followed by entropy - coded data ; the length of such a marker does not include the entropy - coded data .
Note that consecutive 0xFF bytes are used as fill bytes for padding purposes , although this fill byte padding
should only ever take place for markers immediately following entropy - coded scan data ( see JPEG specification section B.1.1.2 and E.1.2 for details ; specifically " In all cases where markers are appended after the compressed data , optional 0xFF fill bytes may precede the marker " ) .
Within the entropy - coded data , after any 0xFF byte , a 0x00 byte is inserted by the encoder before the next byte , so that there does not appear to be a marker where none is intended , preventing framing errors .
Decoders must skip this 0x00 byte .
This technique , called byte stuffing ( see JPEG specification section F.1.2.3 ) , is only applied to the entropy - coded data , not to marker payload data .
Note however that entropy - coded data has a few markers of its own ; specifically the Reset markers ( 0xD0 through 0xD7 ) , which are used to isolate independent chunks of entropy - coded data to allow parallel decoding , and encoders are free to insert these Reset markers at regular intervals ( although not all encoders do this ) .
+ Common JPEG markers !
Short name !
Bytes !
Payload !
Name !
Comments !
SOI !
SOF0 !
SOF2 !
DHT !
DQT !
DRI !
SOS !
RSTn !
APPn !
COM !
EOI
There are other Start Of Frame markers that introduce other kinds of JPEG encodings .
Since several vendors might use the same APPn marker type , application - specific markers often begin with a standard or vendor name ( e.g. , " Exif " or " Adobe " ) or some other identifying string .
At a restart marker , block - to - block predictor variables are reset , and the bitstream is synchronized to a byte boundary .
Restart markers provide means for recovery after bitstream error , such as transmission over an unreliable network or file corruption .
Since the runs of macroblocks between restart markers may be independently decoded , these runs may be decoded in parallel .
JPEG CODEC EXAMPLE Section::::JPEG codec example .
Although a JPEG file can be encoded in various ways , most commonly it is done with JFIF encoding .
The encoding process consists of several steps :
* The representation of the colors in the image is converted from RGB to , consisting of one luma component ( Y ' ) , representing brightness , and two chroma components , ( C and C ) , representing color .
This step is sometimes skipped .
*
* The resolution of the chroma data is reduced , usually by a factor of 2 or 3 .
This reflects the fact that the eye is less sensitive to fine color details than to fine brightness details .
*
* The image is split into blocks of 8×8 pixels , and for each block , each of the Y , C , and C data undergoes the discrete cosine transform ( DCT ) .
A DCT is similar to a Fourier transform in the sense that it produces a kind of spatial frequency spectrum .
*
* The amplitudes of the frequency components are quantized .
Human vision is much more sensitive to small variations in color or brightness over large areas than to the strength of high - frequency brightness variations .
Therefore , the magnitudes of the high - frequency components are stored with a lower accuracy than the low - frequency components .
The quality setting of the encoder ( for example 50 or 95 on a scale of 0–100 in the Independent JPEG Group 's library ) affects to what extent the resolution of each frequency component is reduced .
If an excessively low quality setting is used , the high - frequency components are discarded altogether .
*
* The resulting data for all 8×8 blocks is further compressed with a lossless algorithm , a variant of Huffman encoding .
*
The decoding process reverses these steps , except the quantization because it is irreversible .
In the remainder of this section , the encoding and decoding processes are described in more detail .
ENCODING Section::::Encoding .
Many of the options in the JPEG standard are not commonly used , and as mentioned above , most image software uses the simpler JFIF format when creating a JPEG file , which among other things specifies the encoding method .
Here is a brief description of one of the more common methods of encoding when applied to an input that has 24 bits per pixel ( eight each of red , green , and blue ) .
This particular option is a lossy data compression method .
COLOR SPACE
TRANSFORMATION
Section::::Color space transformation .
First , the image should be converted from RGB into a different color space called ( or , informally , YCbCr ) .
It has three components
Y ' , C and C : the Y ' component represents the brightness of a pixel , and the C and C components represent the chrominance ( split into blue and red components ) .
This is basically the same color space as used by digital color television as well as digital video including video DVDs , and is similar to the way color is represented in analog PAL video and MAC ( but not by analog NTSC , which uses the YIQ color space ) .
The color space conversion allows greater compression without a significant effect on perceptual image quality ( or greater perceptual image quality for the same compression ) .
The compression is more efficient because the brightness information , which is more important to the eventual perceptual quality of the image , is confined to a single channel .
This more closely corresponds to the perception of color in the human visual system .
The color transformation also improves compression by statistical decorrelation .
A particular conversion to is specified in the JFIF standard , and should be performed for the resulting JPEG file to have maximum compatibility .
However , some JPEG implementations in " highest quality " mode do not apply this step and instead keep the color information in the RGB color model , where the image is stored in separate channels for red , green and blue brightness components .
This results in less efficient compression , and would not likely be used when file size is especially important .
DOWNSAMPLING
Section::::Downsampling .
Due to the densities of color- and brightness - sensitive receptors in the human eye , humans can see considerably more fine detail in the brightness of an image ( the Y ' component ) than in the hue and color saturation of an image ( the Cb and Cr components ) .
Using this knowledge , encoders can be designed to compress images more efficiently .
The transformation into the color model enables the next usual step , which is to reduce the spatial resolution of the Cb and Cr components ( called " downsampling " or " chroma subsampling " ) .
The ratios at which the downsampling is ordinarily done for JPEG images are ( no downsampling ) ,
( reduction by a factor of 2 in the horizontal direction ) , or ( most commonly )
( reduction by a factor of 2 in both the horizontal and vertical directions ) .
For the rest of the compression process , Y ' , Cb and Cr are processed separately and in a very similar manner .
BLOCK SPLITTING Section::::Block splitting .
After subsampling , each channel must be split into 8×8 blocks .
Depending on chroma subsampling , this yields Minimum Coded Unit ( MCU ) blocks of size 8×8 ( 4:4:4 – no subsampling ) , 16×8
( 4:2:2 ) , or most commonly 16×16 ( 4:2:0 ) .
In video compression MCUs are called macroblocks .
If the data for a channel does not represent an integer number of blocks then the encoder must fill the remaining area of the incomplete blocks with some form of dummy data .
Filling the edges with a fixed color ( for example , black ) can create ringing artifacts along the visible part of the border ; repeating the edge pixels is a common technique that reduces ( but does not necessarily completely eliminate ) such artifacts , and more sophisticated border filling techniques can also be applied .
DISCRETE COSINE
TRANSFORM
Section::::Discrete cosine transform .
Next , each 8×8 block of each component ( Y , Cb , Cr ) is converted to a frequency - domain representation , using a normalized , two - dimensional type - II discrete cosine transform ( DCT ) , see Citation 1 in discrete cosine transform .
The DCT is sometimes referred to as " type - II DCT " in the context of a family of transforms as in discrete cosine transform , and the corresponding inverse ( IDCT ) is denoted as " type - III DCT " .
As an example , one such 8×8 8-bit subimage might be : Before computing the DCT of the 8×8 block , its values are shifted from a positive range to one centered on zero .
For an 8-bit image , each entry in the original block falls in the range
formula_2 .
The midpoint of the range ( in this case , the value 128 ) is subtracted from each entry to produce a data range that is centered on zero , so that the modified range is formula_3 .
This step reduces the dynamic range requirements in the DCT processing stage that follows .
This step results in the following values : The next step is to take the two - dimensional DCT , which is given by : where * formula_6 is the horizontal spatial frequency , for the integers formula_7 .
*
formula_8 is the vertical spatial frequency , for the integers formula_9 .
*
formula_10 is a normalizing scale factor to make the transformation orthonormal *
formula_11 is the pixel value at coordinates
formula_12
*
formula_13 is the DCT coefficient at coordinates
formula_14
If we perform this transformation on our matrix above , we get the following ( rounded to the nearest two digits beyond the decimal point ) : Note the top - left corner entry with the rather large magnitude .
This is the DC coefficient ( also called the constant component ) , which defines the basic hue for the entire block .
The remaining 63 coefficients are the AC coefficients ( also called the alternating components ) .
The advantage of the DCT is its tendency to aggregate most of the signal in one corner of the result , as may be seen above .
The quantization step to follow accentuates this effect while simultaneously reducing the overall size of the DCT coefficients , resulting in a signal that is easy to compress efficiently in the entropy stage .
The DCT temporarily increases the bit - depth of the data , since the DCT coefficients of an 8-bit / component image take up to 11 or more bits ( depending on fidelity of the DCT calculation ) to store .
This may force the codec to temporarily use 16-bit numbers to hold these coefficients , doubling the size of the image representation at this point ; these values are typically reduced back to 8-bit values by the quantization step .
The temporary increase in size at this stage is not a performance concern for most JPEG implementations , since typically only a very small part of the image is stored in full DCT form at any given time during the image encoding or decoding process .
QUANTIZATION Section::::Quantization .
The human eye is good at seeing small differences in brightness over a relatively large area , but not so good at distinguishing the exact strength of a high frequency brightness variation .
This allows one to greatly reduce the amount of information in the high frequency components .
This is done by simply dividing each component in the frequency domain by a constant for that component , and then rounding to the nearest integer .
This rounding operation is the only lossy operation in the whole process ( other than chroma subsampling ) if the DCT computation is performed with sufficiently high precision .
As a result of this , it is typically the case that many of the higher frequency components are rounded to zero , and many of the rest become small positive or negative numbers , which take many fewer bits to represent .
The elements in the quantization matrix control the compression ratio , with larger values producing greater compression .
A typical quantization matrix ( for a quality of 50 % as specified in the original JPEG Standard ) , is as follows : The quantized DCT coefficients are computed with where formula_18 is the unquantized DCT coefficients ; formula_19 is the quantization matrix above ; and formula_20 is the quantized DCT coefficients .
Using this quantization matrix with the DCT coefficient matrix from above results in :
For example , using −415 ( the DC coefficient ) and rounding to the nearest integer Notice that most of the higher - frequency elements of the sub - block ( i.e. , those with an x or y spatial frequency greater than 4 ) are compressed into zero values .
ENTROPY CODING
Section::::Entropy coding .
Entropy coding is a special form of lossless data compression .
It involves arranging the image components in a " zigzag " order employing run - length encoding ( RLE ) algorithm that groups similar frequencies together , inserting length coding zeros , and then using Huffman coding on what is left .
The JPEG standard also allows , but does not require , decoders to support the use of arithmetic coding , which is mathematically superior to Huffman coding .
However , this feature has rarely been used , as it was historically covered by patent
* is the non - zero , quantized AC coefficient .
* RUNLENGTH is the number of zeroes that came before this non - zero AC coefficient .
* SIZE is the number of bits required to represent .
* AMPLITUDE is the bit - representation of .
The run - length encoding works by examining each non - zero AC coefficient and determining how many zeroes came before the previous AC coefficient .
With this information , two symbols are created : !
Symbol 1 Symbol 2 Both RUNLENGTH and SIZE rest on the same byte , meaning that each only contains four bits of information .
The higher bits deal with the number of zeroes , while the lower bits denote the number of bits necessary to encode the value of .
This has the immediate implication of Symbol 1 being only able store information regarding the first 15 zeroes preceding the non - zero AC coefficient .
However , JPEG defines two special Huffman code words .
One is for ending the sequence prematurely when the remaining coefficients are zero ( called " End - of - Block " or " EOB " ) , and another when the run of zeroes goes beyond 15 before reaching a non - zero AC coefficient .
In such a case where 16 zeroes are encountered before a given non - zero AC coefficient , Symbol 1 is encoded " specially " as : ( 15 , 0)(0 ) .
The overall process continues until " EOB " denoted by ( 0 , 0 ) is reached .
With this in mind , the sequence from earlier becomes : From here , frequency calculations are made based on occurrences of the coefficients .
In our example block , most of the quantized coefficients are small numbers that are not preceded immediately by a zero coefficient .
These more - frequent cases will be represented by shorter code words .
COMPRESSION RATIO AND ARTIFACTS Section::::Compression ratio and artifacts .
The resulting compression ratio can be varied according to need by being more or less aggressive in the divisors used in the quantization phase .
Ten to one compression usually results in an image that can not be distinguished by eye from the original .
A compression ratio of 100:1 is usually possible , but will look distinctly artifacted compared to the original .
The appropriate level of compression depends on the use to which the image will be put .
Those who use the World Wide Web may be familiar with the irregularities known as compression artifacts that appear in JPEG images , which may take the form of noise around contrasting edges ( especially curves and corners ) , or " blocky " images .
These are due to the quantization step of the JPEG algorithm .
They are especially noticeable around sharp corners between contrasting colors ( text is a good example , as it contains many such corners ) .
The analogous artifacts in MPEG video are referred to as mosquito noise , as the resulting " edge busyness " and spurious dots , which change over time , resemble mosquitoes swarming around the object .
These artifacts can be reduced by choosing a lower level of compression ; they may be completely avoided by saving an image using a lossless file format , though this will result in a larger file size .
The images created with ray - tracing programs have noticeable blocky shapes on the terrain .
Certain low - intensity compression artifacts might be acceptable when simply viewing the images , but can be emphasized if the image is subsequently processed , usually resulting in unacceptable quality .
Consider the example below , demonstrating the effect of lossy compression on an edge detection processing step . !
Image ! !
Lossless compression ! !
Lossy compression !
Original !
Processed byCanny edge detector
Some programs allow the user to vary the amount by which individual blocks are compressed .
Stronger compression is applied to areas of the image that show fewer artifacts .
This way it is possible to manually reduce JPEG file size with less loss of quality .
Since the quantization stage always results in a loss of information , JPEG standard is always a lossy compression codec .
( Information is lost both in quantizing and rounding of the floating - point numbers . )
Even if the quantization matrix is a matrix of ones , information will still be lost in the rounding step .
DECODING
Section::::Decoding .
Decoding to display the image consists of doing all the above in reverse .
Taking the DCT coefficient matrix ( after adding the difference of the DC coefficient back in ) and taking the entry - for - entry product with the quantization matrix from above results in which closely resembles the original DCT coefficient matrix for the top - left portion .
The next step is to take the two - dimensional inverse DCT ( a 2D type - III DCT ) , which is given by :
formula_44 where * formula_45 is the pixel row , for the integers formula_46 .
*
formula_47 is the pixel column , for the integers formula_48 .
*
formula_49 is defined as above , for the integers formula_7 .
*
formula_51 is the reconstructed approximate coefficient at coordinates
formula_14
*
formula_53 is the reconstructed pixel value at coordinates formula_12 Rounding the output to integer values (
since the original had integer values ) results in an image with values ( still shifted down by 128 ) and adding 128 to each entry
This is the decompressed subimage .
In general , the decompression process may produce values outside the original input range of formula_2 .
If this occurs , the decoder needs to clip the output values so as to keep them within that range to prevent overflow when storing the decompressed image with the original bit depth .
The decompressed subimage can be compared to the original subimage ( also see images to the right ) by taking the difference ( original − uncompressed ) results in the following error values : with an average absolute error of about 5 values per pixels ( i.e. , formula_59 ) .
The error is most noticeable in the bottom - left corner where the bottom - left pixel becomes darker than the pixel to its immediate right .
REQUIRED PRECISION Section::::Required precision .
The encoding description in the JPEG standard does not fix the precision needed for the output compressed image .
However , the JPEG standard ( and the similar MPEG standards ) includes some precision requirements for the decoding , including all parts of the decoding process ( variable length decoding , inverse DCT , dequantization , renormalization of outputs ) ; the output from the reference algorithm must not exceed : * a maximum of one bit of difference for each pixel component * low mean square error over each 8×8-pixel block
* very low mean error over each 8×8-pixel block
* very low mean square error over the whole image
* extremely low mean error over the whole image
These assertions are tested on a large set of randomized input images , to handle the worst cases .
The former IEEE 1180–1990 standard contained some similar precision requirements .
The precision has a consequence on the implementation of decoders , and it is critical because some encoding processes ( notably used for encoding sequences of images like MPEG ) need to be able to construct , on the encoder side , a reference decoded image .
In order to support 8-bit precision per pixel component output , dequantization and inverse DCT transforms are typically implemented with at least 14-bit precision in optimized decoders .
EFFECTS OF JPEG COMPRESSION Section::::Effects of JPEG compression .
JPEG compression artifacts blend well into photographs with detailed non - uniform textures , allowing higher compression ratios .
Notice how a higher compression ratio first affects the high - frequency textures in the upper - left corner of the image , and how the contrasting lines become more fuzzy .
The very high compression ratio severely affects the quality of the image , although the overall colors and image form are still recognizable .
However , the precision of colors suffer less ( for a human eye ) than the precision of contours ( based on luminance ) .
This justifies the fact that images should be first transformed in a color model separating the luminance from the chromatic information , before subsampling the chromatic planes ( which may also use lower quality quantization ) in order to preserve the precision of the luminance plane with more information bits .
SAMPLE PHOTOGRAPHS Section::::Sample photographs .
For information , the uncompressed 24-bit RGB bitmap image below ( 73,242 pixels ) would require 219,726 bytes ( excluding all other information headers ) .
The filesizes indicated below include the internal JPEG information headers and some metadata .
For highest quality images ( Q=100 ) , about 8.25 bits per color pixel is required .
On grayscale images , a minimum of 6.5 bits per pixel is enough ( a comparable Q=100 quality color information requires about 25 % more encoded bits ) .
The highest quality image below ( Q=100 ) is encoded at nine bits per color pixel , the medium quality image ( Q=25 ) uses one bit per color pixel .
For most applications , the quality factor should not go below 0.75 bit per pixel ( Q=12.5 ) , as demonstrated by the low quality image .
The image at lowest quality uses only 0.13 bit per pixel , and displays very poor color .
This is useful when the image will be displayed in a significantly scaled - down size .
A method for creating better quantization matrices for a given image quality using PSNR instead of the Q factor is described in Minguillón & Pujol ( 2001 ) .
+ align="bottom
" Note : The above images are not IEEE / CCIR / EBU test images , and the encoder settings are not specified or available . !
Image ! !
Quality ! !
Size ( bytes ) ! !
Compression ratio ! !
Comment
The medium quality photo uses only 4.3 % of the storage space required for the uncompressed image , but has little noticeable loss of detail or visible artifacts .
However , once a certain threshold of compression is passed , compressed images show increasingly visible defects .
See the article on rate – distortion theory for a mathematical explanation of this threshold effect .
A particular limitation of JPEG in this regard is its non - overlapped 8×8 block transform structure .
More modern designs such as JPEG 2000 and JPEG XR exhibit a more graceful degradation of quality as the bit usage decreases – by using transforms with a larger spatial extent for the lower frequency coefficients and by using overlapping transform basis functions .
LOSSLESS FURTHER COMPRESSION Section::::Lossless further compression .
From 2004 to 2008 , new research emerged on ways to further compress the data contained in JPEG images without modifying the represented image .
This has applications in scenarios where the original image is only available in JPEG format , and its size needs to be reduced for archiving or transmission .
Standard general - purpose compression tools can not significantly compress JPEG files .
Typically , such schemes take advantage of improvements to the naive scheme for coding DCT coefficients , which fails to take into account :
* Correlations between magnitudes of adjacent coefficients in the same block ; * Correlations between magnitudes of the same coefficient in adjacent blocks ; * Correlations between magnitudes of the same coefficient / block in different channels ; * The DC coefficients when taken together resemble a downscale version of the original image multiplied by a scaling factor .
Well - known schemes for lossless coding of continuous - tone images can be applied , achieving somewhat better compression than the Huffman coded DPCM used in JPEG .
Some standard but rarely used options already exist in JPEG to improve the efficiency of coding DCT coefficients : the arithmetic coding option , and the progressive coding option ( which produces lower bitrates because values for each coefficient are coded independently , and each coefficient has a significantly different distribution ) .
Modern methods have improved on these techniques by reordering coefficients to group coefficients of larger magnitude together ; using adjacent coefficients and blocks to predict new coefficient values ; dividing blocks or coefficients up among a small number of independently coded models based on their statistics and adjacent values ; and most recently , by decoding blocks , predicting subsequent blocks in the spatial domain , and then encoding these to generate predictions for DCT coefficients .
Typically , such methods can compress existing JPEG files between 15 and 25 percent , and for JPEGs compressed at low - quality settings , can produce improvements of up to 65 % .
A freely available tool called packJPG is based on the 2007 paper " Improved Redundancy Reduction for JPEG Files . "
DERIVED FORMATS FOR STEREOSCOPIC 3D
JPEG STEREOSCOPIC Section::::Derived formats for stereoscopic 3D. Section::::JPEG Stereoscopic .
JPS is a stereoscopic JPEG image used for creating 3D effects from 2D images .
It contains two static images , one for the left eye and one for the right eye ; encoded as two side - by - side images in a single JPG file .
JPEG Stereoscopic ( JPS , extension .jps ) is a JPEG - based format for stereoscopic images .
It has a range of configurations stored in the JPEG APP3 marker field , but usually contains one image of double width , representing two images of identical size in cross - eyed ( i.e. left frame on the right half of the image and vice versa ) side - by - side arrangement .
This file format can be viewed as a JPEG without any special software , or can be processed for rendering in other modes .
JPEG MULTI - PICTURE FORMAT Section::::JPEG Multi - Picture Format .
JPEG Multi - Picture Format ( MPO , extension .mpo ) is a JPEG - based format for storing multiple images in a single file .
It contains two or more JPEG files concatenated together .
It also defines a JPEG APP2 marker segment for image description .
Various devices use it to store 3D images , such as Fujifilm FinePix Real 3D W1 , HTC Evo 3D , JVC GY - HMZ1U
AVCHD / MVC extension camcorder , Nintendo 3DS , Panasonic Lumix DMC - TZ20 , DMC - TZ30 , DMC - TZ60 , DMC - TS4 ( FT4 ) , and Sony DSC -
HX7V. Other devices use it to store " preview images " that can be displayed on a TV .
In the last few years , due to the growing use of stereoscopic images , much effort has been spent by the scientific community to develop algorithms for stereoscopic image compression .
PATENT ISSUES Section::::Patent issues .
In 2002 , Forgent Networks asserted that it owned and would enforce patent rights on the JPEG technology , arising from a patent that had been filed on October 27 , 1986 , and granted on October 6 , 1987 ( ) .
The announcement created a furor reminiscent of Unisys ' attempts to assert its rights over the GIF image compression standard .
The JPEG committee investigated the patent claims in 2002 and were of the opinion that they were invalidated by prior art .
Others also concluded that Forgent did not have a patent that covered JPEG .
Nevertheless , between 2002 and 2004 Forgent was able to obtain about US$ 105 million by licensing their patent to some 30 companies .
In April 2004 , Forgent sued 31 other companies to enforce further license payments .
In July of the same year , a consortium of 21 large computer companies filed a countersuit , with the goal of invalidating the patent .
In addition , Microsoft launched a separate lawsuit against Forgent in April 2005 .
In February 2006 , the United States Patent and Trademark Office agreed to re - examine Forgent 's JPEG patent at the request of the Public Patent Foundation .
On May 26 , 2006 the USPTO found the patent invalid based on prior art .
The USPTO also found that Forgent knew about the prior art , yet it intentionally avoided telling the Patent Office .
This makes any appeal to reinstate the patent highly unlikely to succeed .
Forgent also possesses a similar patent granted by the European Patent Office in 1994 , though it is unclear how enforceable it is .
As of October 27 , 2006 , the U.S. patent 's 20-year term appears to have expired , and in November 2006 , Forgent agreed to abandon enforcement of patent claims against use of the JPEG standard .
The JPEG committee has as one of its explicit goals that their standards ( in particular their baseline methods ) be implementable without payment of license fees , and they have secured appropriate license rights for their JPEG 2000 standard from over 20 large organizations .
Beginning in August 2007 , another company , Global Patent Holdings , LLC claimed that its patent ( ) issued in 1993 , is infringed by the downloading of JPEG images on either a website or through e - mail .
If not invalidated , this patent could apply to any website that displays JPEG images .
The patent was under reexamination by the U.S. Patent and Trademark Office from 2000 - 2007 ; in July 2007 , the Patent Office revoked all of the original claims of the patent but found that an additional claim proposed by Global Patent Holdings ( claim 17 ) was valid .
Global Patent Holdings then filed a number of lawsuits based on claim 17 of its patent .
In its first two lawsuits following the reexamination , both filed in Chicago , Illinois , Global Patent Holdings sued the Green Bay Packers , CDW , Motorola , Apple , Orbitz , Officemax , Caterpillar , Kraft and Peapod as defendants .
A third lawsuit was filed on December 5 , 2007 in South Florida against ADT Security Services , AutoNation , Florida Crystals Corp. , HearUSA , MovieTickets.com , Ocwen Financial Corp. and Tire Kingdom , and a fourth lawsuit on January 8 , 2008 in South Florida against the Boca Raton Resort & Club .
A fifth lawsuit was filed against Global Patent Holdings in Nevada .
That lawsuit was filed by Zappos.com , Inc. , which was allegedly threatened by Global Patent Holdings , and sought a judicial declaration that the ' 341 patent is invalid and not infringed .
Global Patent Holdings had also used the ' 341 patent to sue or threaten outspoken critics of broad software patents , including Gregory Aharonian and the anonymous operator of a website blog known as the " Patent Troll Tracker . "
On December 21 , 2007 , patent lawyer Vernon Francissen of Chicago asked the U.S. Patent and Trademark Office to reexamine the sole remaining claim of the ' 341 patent on the basis of new prior art .
On March 5 , 2008 , the U.S. Patent and Trademark Office agreed to reexamine the ' 341 patent , finding that the new prior art raised substantial new questions regarding the patent 's validity .
In light of the reexamination , the accused infringers in four of the five pending lawsuits have filed motions to suspend ( stay ) their cases until completion of the U.S. Patent and Trademark Office 's review of the ' 341 patent .
On April 23 , 2008 , a judge presiding over the two lawsuits in Chicago , Illinois granted the motions in those cases .
On July 22 , 2008 , the Patent Office issued the first " Office Action " of the second reexamination , finding the claim invalid based on nineteen separate grounds .
On Nov. 24 , 2009 , a Reexamination Certificate was issued cancelling all claims .
Beginning in 2011 and continuing as of early 2013 , an entity known as Princeton Digital Image Corporation , based in Eastern Texas , began suing large numbers of companies for alleged infringement of .
Princeton claims that the JPEG image compression standard infringes the ' 056 patent and has sued large numbers of websites , retailers , camera and device manufacturers and resellers .
The patent was originally owned and assigned to General Electric .
The patent expired in December 2007 , but Princeton has sued large numbers of companies for " past infringement " of this patent .
( Under U.S. patent laws , a patent owner can sue for " past infringement " up to six years before the filing of a lawsuit , so Princeton could theoretically have continued suing companies until December 2013 . )
As of March 2013 , Princeton had suits pending in New York and Delaware against more than 55 companies .
General Electric 's involvement in the suit is unknown , although court records indicate that it assigned the patent to Princeton in 2009 and retains certain rights in the patent .
IMPLEMENTATIONS Section::::Implementations .
A very important implementation of a JPEG codec is the free programming library libjpeg of the Independent JPEG Group .
It was first published in 1991 and was key for the success of the standard .
This library or a direct derivative of it is used in countless applications .
Recent versions introduce proprietary extension not compatible with ISO / IEC standards .
In March 2017 , Google released the open source project Guetzli , which trades off a much longer encoding time for better appearance and smaller file size ( similar to what Zopfli does for PNG and other lossless data formats ) .
ISO / IEC Joint Photography Experts Group maintains a reference software implementation which can encode both base JPEG ( ISO / IEC 10918 - 1 and 18477 - 1 ) and JPEG XT extensions ( ISO / IEC 18477 Parts 2 and 6 - 9 ) , as well as JPEG - LS ( ISO / IEC 14495 ) .
JPEG XT Section::::JPEG XT .
JPEG XT ( ISO / IEC 18477 ) was published in June 2015 ; it extends base JPEG format with support for higher integer bit depths ( up to 16 bit ) , high dynamic range imaging and floating - point coding , lossless coding , and alpha channel coding .
Extensions are backward compatible with the base JPEG / JFIF file format and 8-bit lossy compressed image .
JPEG XT uses an extensible file format based on JFIF .
Extension layers are used to modify the JPEG 8-bit base layer and restore the high - resolution image .
Existing software is forward compatible and can read the JPEG XT binary stream , though it would only decode the base 8-bit layer .
JPEG XL Section::::JPEG XL .
Since August 2017 , JTC1 / SC29 / WG1 issued a series of draft calls for proposals on JPEG XL the next generation image compression standard with substantially better compression efficiency ( 60 % improvement ) comparing to JPEG .
The standard is expected to follow still image compression performance shown by HEVC HM , Daala and WebP.
The core requirements include support for very high - resolution images ( at least 40 MP ) , 8–10 bits per component , RGB / YCbCr / ICtCp color encoding , animated images , alpha channel coding , Rec.709 color space ( sRGB ) and gamma function ( 2.4-power ) , Rec.2100 wide color gamut color space ( Rec.2020 ) and high dynamic range transfer functions ( PQ and HLG ) , and high - quality compression of synthetic images , such as bitmap fonts and gradients .
The standard should also offer higher bit depths ( 12–16 bit integer and floating point ) , additional color spaces and transfer functions ( such as Log C from Arri ) , embedded preview images , lossless alpha channel encoding , image region coding , and low - complexity encoding .
Any patented technologies would be licensed on a royalty - free basis .
The proposals should be submitted by September 2018 , with current target publication date in October 2019 .
SEE ALSO
* Better Portable Graphics , a new format based on intra - frame encoding of the HEVC * C - Cube , an early implementer of JPEG in chip form * Comparison of graphics file formats
* Comparison of layout engines ( graphics )
* Deblocking filter ( video ) , the similar deblocking methods could be applied to JPEG
* Design rule for Camera File system ( DCF )
* File extensions
* Graphics editing program * High Efficiency Image File Format , image container format for HEVC and other image coding formats
* Image compression
* Image file formats * JPEG 2000
* Lenna ( test image ) , the traditional standard image used to test image processing algorithms
* Lossless Image Codec FELICS *
Motion
JPEG * PGF
* PNG * WebP
REFERENCES
EXTERNAL LINKS * JPEG Standard ( JPEG ISO / IEC 10918 - 1 ITU - T Recommendation T.81 ) at W3.org * Official Joint Photographic Experts Group ( JPEG ) site * JFIF File Format at W3.org
* JPEG viewer in 250 lines of easy to understand Python code
* Example images over the full range of quantization levels from 1 to 100 at visengi.com * Public domain JPEG compressor in a single C++ source file , along with a matching decompressor at code.google.com * JPEG decoder open source code , copyright ( C ) 1995–1997 , Thomas G. Lane